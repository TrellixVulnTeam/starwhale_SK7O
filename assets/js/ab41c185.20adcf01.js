"use strict";(self.webpackChunkstarwhale_docs=self.webpackChunkstarwhale_docs||[]).push([[402],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return m}});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var s=n.createContext({}),d=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,s=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=d(a),m=l,h=u["".concat(s,".").concat(m)]||u[m]||c[m]||r;return a?n.createElement(h,i(i({ref:t},p),{},{components:a})):n.createElement(h,i({ref:t},p))}));function m(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,i=new Array(r);i[0]=u;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:l,i[1]=o;for(var d=2;d<r;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},9176:function(e,t,a){a.r(t),a.d(t,{assets:function(){return p},contentTitle:function(){return s},default:function(){return m},frontMatter:function(){return o},metadata:function(){return d},toc:function(){return c}});var n=a(7462),l=a(3366),r=(a(7294),a(3905)),i=["components"],o={title:"Image Classification on CIFAR-10"},s=void 0,d={unversionedId:"tutorials/cifar10",id:"tutorials/cifar10",title:"Image Classification on CIFAR-10",description:"This example will illustrate how to evaluate a pre-trained classification model on StarWhale under 5 steps.",source:"@site/docs/tutorials/cifar10.md",sourceDirName:"tutorials",slug:"/tutorials/cifar10",permalink:"/docs/tutorials/cifar10",draft:!1,editUrl:"https://github.com/star-whale/starwhale/tree/main/docs/docs/tutorials/cifar10.md",tags:[],version:"current",frontMatter:{title:"Image Classification on CIFAR-10"},sidebar:"mainSidebar",previous:{title:"Text Classification on AG News dataset",permalink:"/docs/tutorials/ag_news"},next:{title:"Object Detection & segmentation on PeenFudanPed dataset",permalink:"/docs/tutorials/pfp"}},p={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Train the model",id:"train-the-model",level:2},{value:"Slice the test dataset using Starwhale protocol",id:"slice-the-test-dataset-using-starwhale-protocol",level:2},{value:"Implement the inference method and evaluation metrics computing method",id:"implement-the-inference-method-and-evaluation-metrics-computing-method",level:2},{value:"Implement ppl",id:"implement-ppl",level:3},{value:"Implement cmp",id:"implement-cmp",level:3},{value:"Build Dataset and Model",id:"build-dataset-and-model",level:2},{value:"Build Dataset",id:"build-dataset",level:3},{value:"Build Model",id:"build-model",level:3},{value:"Run the evaluation job and see the metrics",id:"run-the-evaluation-job-and-see-the-metrics",level:2}],u={toc:c};function m(e){var t=e.components,o=(0,l.Z)(e,i);return(0,r.kt)("wrapper",(0,n.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"This example will illustrate how to evaluate a pre-trained classification model on StarWhale under 5 steps."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Train the model"),(0,r.kt)("li",{parentName:"ol"},"Implement the dataset slicing method"),(0,r.kt)("li",{parentName:"ol"},"Implement the inference method and evaluation metrics computing method"),(0,r.kt)("li",{parentName:"ol"},"Build Dataset and Model"),(0,r.kt)("li",{parentName:"ol"},"Run the evaluation job and see the metrics")),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Assume that you have Python3.7 or above installed")),(0,r.kt)("p",null,"Clone starwhale repo and install the requirements"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},"git clone https://github.com/star-whale/starwhale.git\ncd starwhale/example/cifar10\n#create your virtual environment if needed\npip install -r requirements.txt\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\ud83d\udca1 If you are from China mainland you're strongly recommended using a proxy")),(0,r.kt)("h2",{id:"train-the-model"},"Train the model"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"The training code in this repo is sourced from ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"},"https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},"mkdir models\ncd code\npython3 train.py\n")),(0,r.kt)("p",null,"The training process is rather slow on your laptop. You could reduce the train epochs in ",(0,r.kt)("inlineCode",{parentName:"p"},"train.py")," to make it faster."),(0,r.kt)("p",null,"You will get the logs below:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n100.0%\nExtracting ../data/cifar-10-python.tar.gz to ../data\n[1,  2000] loss: 2.180\n[1,  4000] loss: 1.817\n......\n......\n[10, 12000] loss: 0.763\nFinished Training\n")),(0,r.kt)("p",null,"Great! Now you have your model trained and saved. You could see it locates in the ",(0,r.kt)("inlineCode",{parentName:"p"},"models")," directory."),(0,r.kt)("h2",{id:"slice-the-test-dataset-using-starwhale-protocol"},"Slice the test dataset using Starwhale protocol"),(0,r.kt)("p",null,"In the training section we got a dataset called ",(0,r.kt)("a",{parentName:"p",href:"https://www.cs.toronto.edu/~kriz/cifar.html"},"CIFA-10"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},"$ cd ../data\n$ ls\ncifar-10-batches-py  cifar-10-python.tar.gz\n$ ls cifar-10-batches-py\nbatches.meta  data_batch_1  data_batch_2  data_batch_3  data_batch_4  data_batch_5  readme.html  test_batch\n")),(0,r.kt)("p",null,"The test part of the dataset is a single file of size 30MB called ",(0,r.kt)("inlineCode",{parentName:"p"},"test_batch")," which contains 10,000 images and labels."),(0,r.kt)("p",null,"Before version ",(0,r.kt)("inlineCode",{parentName:"p"},"0.1.2b7")," StarWhale will slice the dataset into chunks where reside the batched images and batched labels. You need to tell StarWhale how to yield batches of byte arrays from each dataset file."),(0,r.kt)("p",null,"In this example we will ",(0,r.kt)("inlineCode",{parentName:"p"},"unpickle")," the dataset and get the numpy arrays of each image and a list for all the labels. Then transform them into byte arrays."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"class CIFAR10Slicer(BuildExecutor):\n\n    def iter_data_slice(self, path: str):\n        content_dict = unpickle(path)\n        data_numpy = content_dict.get(b'data')\n        idx = 0\n        data_size = len(data_numpy)\n        while True:\n            last_idx = idx\n            idx = idx + self._batch\n            if idx > data_size:\n                break\n            yield data_numpy[last_idx:idx].tobytes()\n\n    def iter_label_slice(self, path: str):\n        content_dict = unpickle(path)\n        labels_list = content_dict.get(b'labels')\n        idx = 0\n        data_size = len(labels_list)\n        while True:\n            last_idx = idx\n            idx = idx + self._batch\n            if idx > data_size:\n                break\n            yield bytes(labels_list[last_idx:idx])\n")),(0,r.kt)("p",null,"You need to extend the abstract class ",(0,r.kt)("inlineCode",{parentName:"p"},"BuildExecutor")," so that your dataset could be used by starwhale. The ",(0,r.kt)("inlineCode",{parentName:"p"},"path")," argument is a file that matches ",(0,r.kt)("inlineCode",{parentName:"p"},"data_filter")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"label_filter")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"${code_base}/example/cifar10/dataset.yaml"),". You could see the filters in this example both are ",(0,r.kt)("inlineCode",{parentName:"p"},"test_batch")),(0,r.kt)("h2",{id:"implement-the-inference-method-and-evaluation-metrics-computing-method"},"Implement the inference method and evaluation metrics computing method"),(0,r.kt)("p",null,"The inference method is called ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl")," and the evaluation metrics computing method is called ",(0,r.kt)("inlineCode",{parentName:"p"},"cmp"),".\nHere is the code snap from ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl.py")," where both methods are implemented. You need to extend the abstract class ",(0,r.kt)("inlineCode",{parentName:"p"},"PipelineHandler")," so that you could receive the byte arrays you just transformed in last step."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'class CIFAR10Inference(PipelineHandler):\n\n    def __init__(self, device="cpu") -> None:\n        super().__init__(merge_label=True, ignore_error=True)\n        self.device = torch.device(device)\n        self.model = self._load_model(self.device)\n\n    def ppl(self, data, batch_size, **kw):\n        data = self._pre(data, batch_size)\n        output = self.model(data)\n        return self._post(output)\n\n    def handle_label(self, label, batch_size, **kw):\n        return [int(l) for l in label]\n\n    @multi_classification(\n        confusion_matrix_normalize="all",\n        show_hamming_loss=True,\n        show_cohen_kappa_score=True,\n        show_roc_auc=True,\n        all_labels=[i for i in range(0, 10)],\n    )\n    def cmp(self, _data_loader):\n        _result, _label, _pr = [], [], []\n        for _data in _data_loader:\n            _label.extend([int(l) for l in _data["label"]])\n            _result.extend([int(l) for l in _data["result"]])\n            _pr.extend([l for l in _data["pr"]])\n        return _label, _result, _pr\n\n    def _pre(self, input: bytes, batch_size: int):\n        images = []\n        from_buffer = np.frombuffer(input, \'uint8\')\n        shape = (batch_size, ONE_IMAGE_SIZE)\n        batch_numpy_flatten_data = from_buffer.reshape(shape)\n        batch_numpy_flatten_data = np.vstack([batch_numpy_flatten_data]).reshape(-1, 3, 32, 32)\n        batch_numpy_flatten_data = batch_numpy_flatten_data.transpose((0, 2, 3, 1))\n        shape_image = (WIDTH_IMAGE, HEIGHT_IMAGE, CHANNEL_IMAGE)\n        for i in range(0, batch_size):\n            numpy_flatten_data_i_ = batch_numpy_flatten_data[i]\n            _image = Image.fromarray(numpy_flatten_data_i_.reshape(shape_image))\n            _image = transforms.Compose(\n                [transforms.ToTensor(),\n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])(_image)\n            images.append(_image)\n        return torch.stack(images).to(self.device)\n\n    def _post(self, input):\n        pred_value = input.argmax(1).flatten().tolist()\n        probability_matrix = np.exp(input.tolist()).tolist()\n        return pred_value, probability_matrix\n\n    def _load_model(self, device):\n        model = Net().to(device)\n        model.load_state_dict(torch.load(str(ROOTDIR / "models/cifar_net.pth")))\n        model.eval()\n        print("load cifar_net model, start to inference...")\n        return model\n')),(0,r.kt)("h3",{id:"implement-ppl"},"Implement ppl"),(0,r.kt)("p",null,"StarWhale will feed the byte arrays of one batch to the ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl")," method. And take the output of ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl")," into a ",(0,r.kt)("inlineCode",{parentName:"p"},"inference_result")," dict which looks like"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{"result":[{resultObj1},{resultObj2}],"label":[{labelObj1},{labelObj2}]}\n')),(0,r.kt)("p",null,"Now let's look at how ",(0,r.kt)("inlineCode",{parentName:"p"},"inference_result")," is produced using the byte arrays of one batch."),(0,r.kt)("p",null,"First we load our model trained before use ",(0,r.kt)("inlineCode",{parentName:"p"},"_load_model"),". Then we transform byte array to tensor which could be a valid input for the model use ",(0,r.kt)("inlineCode",{parentName:"p"},"_pre"),".\nAnd then, we do inference. At the end, we convert the output tensor to label use ",(0,r.kt)("inlineCode",{parentName:"p"},"_post")," method.\nBy the way, we also overwrite the ",(0,r.kt)("inlineCode",{parentName:"p"},"handle_label")," method."),(0,r.kt)("p",null,"StarWhale will automatically add result of ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"inference_result.result")," and add result of ",(0,r.kt)("inlineCode",{parentName:"p"},"handle_label")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"inference_result.label"),"."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"inference_result")," is used in the argument of ",(0,r.kt)("inlineCode",{parentName:"p"},"cmp")," which is named ",(0,r.kt)("inlineCode",{parentName:"p"},"_data_loader"),"."),(0,r.kt)("h3",{id:"implement-cmp"},"Implement cmp"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"_data_loader")," is an iterator for ",(0,r.kt)("inlineCode",{parentName:"p"},"result")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"label"),". For a multiple classification problem, it is quite easy for you to implement the ",(0,r.kt)("inlineCode",{parentName:"p"},"cmp")," method:"),(0,r.kt)("p",null,"Just annotate your ",(0,r.kt)("inlineCode",{parentName:"p"},"cmp")," method with ",(0,r.kt)("inlineCode",{parentName:"p"},"multi_classification")," annotation and copy the lines inside it"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'    @multi_classification(\n        confusion_matrix_normalize="all",\n        show_hamming_loss=True,\n        show_cohen_kappa_score=True,\n        show_roc_auc=True,\n        all_labels=[i for i in range(0, 10)],\n    )\n    def cmp(self, _data_loader):\n        _result, _label, _pr = [], [], []\n        for _data in _data_loader:\n            _label.extend([int(l) for l in _data["label"]])\n            _result.extend([int(l) for l in _data["result"]])\n            _pr.extend([l for l in _data["pr"]])\n        return _label, _result, _pr\n')),(0,r.kt)("p",null,"If you need to show ",(0,r.kt)("inlineCode",{parentName:"p"},"roc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"auc"),", you will also need to supply ",(0,r.kt)("inlineCode",{parentName:"p"},"_pr")," in your ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl")," method."),(0,r.kt)("p",null,"By now we have finished all the coding part. Then let's begin the command line part."),(0,r.kt)("h2",{id:"build-dataset-and-model"},"Build Dataset and Model"),(0,r.kt)("h3",{id:"build-dataset"},"Build Dataset"),(0,r.kt)("p",null,"There is some descriptive information needed for StarWhale to build a StarWhale Dataset(SWDS). The information is described by a yaml file like below:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'name: cifar10\nmode: generate\ndata_dir: data\ndata_filter: "test_batch"\nlabel_filter: "test_batch"\n\nprocess: code.data_slicer:CIFAR10Slicer\npip_req: requirements.txt\n\ndesc: CIFAR10 data and label test dataset\n\nattr:\n    batch_size: 50\n    alignment_size: 4k\n    volume_size: 2M\n')),(0,r.kt)("p",null,"Most of the fields are self-explained. The ",(0,r.kt)("inlineCode",{parentName:"p"},"process")," descriptor is used to tell StarWhale that 'Hey, use CIFAR10Slicer to slice the dataset please!'. The ",(0,r.kt)("inlineCode",{parentName:"p"},"data_filter")," is used to tell StarWhale to search files that contain data and named like ",(0,r.kt)("inlineCode",{parentName:"p"},"test_batch")," recursively under ",(0,r.kt)("inlineCode",{parentName:"p"},"data_dir"),". Then StarWhale will use the files searched as input for ",(0,r.kt)("inlineCode",{parentName:"p"},"process"),"."),(0,r.kt)("p",null,"After create the yaml file under ",(0,r.kt)("inlineCode",{parentName:"p"},"${code_base}/example/cifar10/"),", we are ready to do it."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},"$ cd ..\n$ swcli dataset build .\n\ud83c\udd95 swmp version g4ytezbqgfrt\n\ud83d\udcc1 swmp workdir: /home/anda/.cache/starwhale/dataset/cifar10/g4ytezbqgfrtmodche3wcnrupfwta5a\n\ud83d\udc4d try to copy source code files...\n\ud83d\udc7b import <code.data_slicer.CIFAR10Slicer object at 0x7faa927a5fa0> to make swds...\ncleanup done.\n\ud83d\udcab python3.8.13@conda, try to export environment...\n\ud83e\udd16 calculate signature...\n\ud83c\udf3a congratulation! you can run  swcli dataset info cifar10:g4ytezbqgfrtmodche3wcnrupfwta5a\n8 out of 8 steps finished \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 0:00:04\n")),(0,r.kt)("p",null,"One step is left to success."),(0,r.kt)("h3",{id:"build-model"},"Build Model"),(0,r.kt)("p",null,"There is some descriptive information needed for StarWhale to build a StarWhale Model Package(SWMP). The information is described by a yaml file like below:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"version: 1.0\nname: cifar_net\n\nmodel:\n- models/cifar_net.pth\n\nconfig:\n- config/hyperparam.json\n\nrun:\nppl: code.ppl:CIFAR10Inference\npip_req: requirements.txt\ndesc: cifar10 by pytorch\n\ntag:\n- multi_classification\n")),(0,r.kt)("p",null,"Most of the fields are self-explained. The ",(0,r.kt)("inlineCode",{parentName:"p"},"ppl")," descriptor is used to tell StarWhale that 'Hey, run the inference method and cmp method with CIFAR10Inference please!'.\nAfter create the yaml file under ",(0,r.kt)("inlineCode",{parentName:"p"},"${code_base}/example/cifar10/"),", we are ready to do it."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},"$ swcli model build . --skip-gen-env\n\ud83c\udd95 swmp version hfqtimrxgy4g\n\ud83d\udcc1 swmp workdir: /home/anda/.cache/starwhale/workdir/cifar_net/hfqtimrxgy4gcztfgq4gmzten42gc6a\n\ud83d\udc4d try to copy source code files...\n\ud83d\udcab python3.8.13@conda, try to export environment...\n\ud83c\udf3a congratulation! you can run  swcli model info cifar_net:hfqtimrxgy4gcztfgq4gmzten42gc6a\n6 out of 6 steps finished \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 0:00:03\n")),(0,r.kt)("p",null,"There we are. We have finished all the hard parts."),(0,r.kt)("h2",{id:"run-the-evaluation-job-and-see-the-metrics"},"Run the evaluation job and see the metrics"),(0,r.kt)("p",null,"Before we can really evaluate our model, we should copy the runtime, model and dataset to the StarWhale instance.Visit the console, create one job and watch the evaluation metrics."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Create one evaluation job"),"\n",(0,r.kt)("img",{alt:"create evaluation job",src:a(8366).Z,width:"1920",height:"1080"}))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Watch the results"),"\n",(0,r.kt)("img",{alt:"watch the result",src:a(6805).Z,width:"1920",height:"1080"}),"\n",(0,r.kt)("img",{alt:"watch the result",src:a(216).Z,width:"1920",height:"1080"}),"\n",(0,r.kt)("img",{alt:"watch the result",src:a(3951).Z,width:"1920",height:"854"}),"\n",(0,r.kt)("img",{alt:"watch the result",src:a(5671).Z,width:"1920",height:"854"})))),(0,r.kt)("p",null,"Congratulations, we have finished the whole example! From now on, we can update the training method, get a new model, build a new SWMP and evaluate our model from time to time."))}m.isMDXComponent=!0},8366:function(e,t,a){t.Z=a.p+"assets/images/cifar10_create-45d8aeae06b65e04ef158d206a0ccdff.png"},6805:function(e,t,a){t.Z=a.p+"assets/images/cifar10_result1-7bde1f16b4eb1386d5ac700577742b6d.png"},216:function(e,t,a){t.Z=a.p+"assets/images/cifar10_result2-fb20882bcd49bb8ac3c98c22fcf54dbc.png"},3951:function(e,t,a){t.Z=a.p+"assets/images/cifar10_result3-5e48dfdc680091f1ae27f3f5f6515542.png"},5671:function(e,t,a){t.Z=a.p+"assets/images/cifar10_result4-f7fdf8dc550301e4fa01da1ffbd41fd9.png"}}]);